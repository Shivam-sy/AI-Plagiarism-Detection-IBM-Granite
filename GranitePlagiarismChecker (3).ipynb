{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "!pip install --upgrade ibm-watsonx-ai ibm-cos-sdk pandas numpy scikit-learn nltk transformers\n!pip install --upgrade \"ibm-granular-access-sdk[iam-token-manager]\" # For IBM Granite (if you're using it directly with API)\n\nimport nltk\nnltk.download('punkt')\nnltk.download('stopwords')", "metadata": {"id": "1d351eec-ab1e-4c0a-bb47-c7a10bd89e7e"}, "outputs": [{"name": "stdout", "text": "Requirement already satisfied: ibm-watsonx-ai in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (1.3.31)\nCollecting ibm-watsonx-ai\n  Downloading ibm_watsonx_ai-1.3.32-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (2.14.2)\nCollecting ibm-cos-sdk\n  Downloading ibm_cos_sdk-2.14.3.tar.gz (58 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: pandas in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (2.1.4)\nCollecting pandas\n  Downloading pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (1.26.4)\nCollecting numpy\n  Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (1.3.0)\nCollecting scikit-learn\n  Downloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: nltk in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (3.9.1)\nCollecting transformers\n  Downloading transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai) (2.32.4)\nRequirement already satisfied: httpx<0.29,>=0.27 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai) (0.28.1)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai) (1.26.19)\nCollecting pandas\n  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: certifi in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai) (2025.6.15)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai) (0.3.3)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai) (0.8.10)\nRequirement already satisfied: packaging in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai) (23.2)\nRequirement already satisfied: cachetools in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-watsonx-ai) (5.3.3)\nCollecting ibm-cos-sdk-core==2.14.3 (from ibm-cos-sdk)\n  Downloading ibm_cos_sdk_core-2.14.3.tar.gz (1.1 MB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting ibm-cos-sdk-s3transfer==2.14.3 (from ibm-cos-sdk)\n  Downloading ibm_cos_sdk_s3transfer-2.14.3.tar.gz (139 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m139.6/139.6 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: jmespath<=1.0.1,>=0.10.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-cos-sdk) (1.0.1)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from ibm-cos-sdk-core==2.14.3->ibm-cos-sdk) (2.9.0.post0)\nCollecting urllib3 (from ibm-watsonx-ai)\n  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from pandas) (2023.3)\nRequirement already satisfied: scipy>=1.8.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.2.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\nCollecting threadpoolctl>=3.1.0 (from scikit-learn)\n  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: click in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from nltk) (2023.10.3)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from nltk) (4.66.4)\nRequirement already satisfied: filelock in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from transformers) (3.13.1)\nCollecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n  Downloading huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from transformers) (6.0.1)\nCollecting tokenizers<0.22,>=0.21 (from transformers)\n  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nCollecting safetensors>=0.4.3 (from transformers)\n  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nRequirement already satisfied: anyio in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (4.7.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (1.0.9)\nRequirement already satisfied: idna in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (3.7)\nRequirement already satisfied: h11>=0.16 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ibm-watsonx-ai) (0.16.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\nCollecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.9.0->ibm-cos-sdk-core==2.14.3->ibm-cos-sdk) (1.16.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from requests->ibm-watsonx-ai) (2.0.4)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages (from anyio->httpx<0.29,>=0.27->ibm-watsonx-ai) (1.3.0)\nDownloading ibm_watsonx_ai-1.3.32-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m148.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.7 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m154.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.54.1-py3-none-any.whl (11.2 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m148.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m133.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m132.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\nDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m165.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m170.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n  Building wheel for ibm-cos-sdk (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ibm-cos-sdk: filename=ibm_cos_sdk-2.14.3-py3-none-any.whl size=77234 sha256=f8be15a7d8c353e8ea56d17368949d08a7f1f8c40da46e59dbbb7cd3f286a532\n  Stored in directory: /tmp/1000770000/.cache/pip/wheels/56/fa/85/9a1004ed234750540a7a90f34000bc1208e723f3613eaafc2b\n  Building wheel for ibm-cos-sdk-core (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ibm-cos-sdk-core: filename=ibm_cos_sdk_core-2.14.3-py3-none-any.whl size=662104 sha256=1c588fe221765ab00adf9adc522926e75a2b0c8efa0c7733c0f6c988867eb2d3\n  Stored in directory: /tmp/1000770000/.cache/pip/wheels/96/25/ac/fa87dd4aeda7eba0f3e7e891c52f9c92c8b2ea49963119d9df\n  Building wheel for ibm-cos-sdk-s3transfer (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ibm-cos-sdk-s3transfer: filename=ibm_cos_sdk_s3transfer-2.14.3-py3-none-any.whl size=90205 sha256=e26432fe1d258cd33df9a81e55c15e87f7ce969b8e058172ea894d6630f9aed8\n  Stored in directory: /tmp/1000770000/.cache/pip/wheels/c4/03/6f/e85bbf1471a809e7892239f69458cef2cd69ee38fb543339c8\nSuccessfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\nInstalling collected packages: urllib3, threadpoolctl, safetensors, hf-xet, scikit-learn, pandas, ibm-cos-sdk-core, huggingface-hub, tokenizers, ibm-cos-sdk-s3transfer, transformers, ibm-cos-sdk, ibm-watsonx-ai\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.19\n    Uninstalling urllib3-1.26.19:\n      Successfully uninstalled urllib3-1.26.19\n  Attempting uninstall: threadpoolctl\n    Found existing installation: threadpoolctl 2.2.0\n    Uninstalling threadpoolctl-2.2.0:\n      Successfully uninstalled threadpoolctl-2.2.0\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.3.0\n    Uninstalling scikit-learn-1.3.0:\n      Successfully uninstalled scikit-learn-1.3.0\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.1.4\n    Uninstalling pandas-2.1.4:\n      Successfully uninstalled pandas-2.1.4\n  Attempting uninstall: ibm-cos-sdk-core\n    Found existing installation: ibm-cos-sdk-core 2.14.2\n    Uninstalling ibm-cos-sdk-core-2.14.2:\n      Successfully uninstalled ibm-cos-sdk-core-2.14.2\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface_hub 0.29.2\n    Uninstalling huggingface_hub-0.29.2:\n      Successfully uninstalled huggingface_hub-0.29.2\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.15.2\n    Uninstalling tokenizers-0.15.2:\n      Successfully uninstalled tokenizers-0.15.2\n  Attempting uninstall: ibm-cos-sdk-s3transfer\n    Found existing installation: ibm-cos-sdk-s3transfer 2.14.2\n    Uninstalling ibm-cos-sdk-s3transfer-2.14.2:\n      Successfully uninstalled ibm-cos-sdk-s3transfer-2.14.2\n  Attempting uninstall: ibm-cos-sdk\n    Found existing installation: ibm-cos-sdk 2.14.2\n    Uninstalling ibm-cos-sdk-2.14.2:\n      Successfully uninstalled ibm-cos-sdk-2.14.2\n  Attempting uninstall: ibm-watsonx-ai\n    Found existing installation: ibm_watsonx_ai 1.3.31\n    Uninstalling ibm_watsonx_ai-1.3.31:\n      Successfully uninstalled ibm_watsonx_ai-1.3.31\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbotocore 1.32.1 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.5.0 which is incompatible.\ngoogle-auth 2.22.0 requires urllib3<2.0, but you have urllib3 2.5.0 which is incompatible.\nibm-cloud-sdk-core 3.16.7 requires urllib3<2.0.0,>=1.26.0, but you have urllib3 2.5.0 which is incompatible.\nibm-watson-machine-learning 1.0.368 requires pandas<2.2.0,>=0.24.2, but you have pandas 2.2.3 which is incompatible.\nautoai-ts-libs 4.0.18 requires pandas==2.1.*, but you have pandas 2.2.3 which is incompatible.\nautoai-ts-libs 4.0.18 requires scikit-learn==1.3.*, but you have scikit-learn 1.7.1 which is incompatible.\nlale 0.8.4 requires scikit-learn<1.5.0,>=1.0.0, but you have scikit-learn 1.7.1 which is incompatible.\nautoai-libs 2.0.21 requires pandas==2.1.*, but you have pandas 2.2.3 which is incompatible.\nautoai-libs 2.0.21 requires scikit-learn==1.3.*, but you have scikit-learn 1.7.1 which is incompatible.\nibm-watson-openscale 3.0.48 requires pandas<=2.1.9,>=1.4.3, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed hf-xet-1.1.5 huggingface-hub-0.34.3 ibm-cos-sdk-2.14.3 ibm-cos-sdk-core-2.14.3 ibm-cos-sdk-s3transfer-2.14.3 ibm-watsonx-ai-1.3.32 pandas-2.2.3 safetensors-0.5.3 scikit-learn-1.7.1 threadpoolctl-3.6.0 tokenizers-0.21.4 transformers-4.54.1 urllib3-2.5.0\n\u001b[31mERROR: Could not find a version that satisfies the requirement ibm-granular-access-sdk[iam-token-manager] (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for ibm-granular-access-sdk[iam-token-manager]\u001b[0m\u001b[31m\n\u001b[0m", "output_type": "stream"}, {"name": "stderr", "text": "[nltk_data] Downloading package punkt to /home/wsuser/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n[nltk_data] Downloading package stopwords to /home/wsuser/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n", "output_type": "stream"}, {"execution_count": 1, "output_type": "execute_result", "data": {"text/plain": "True"}, "metadata": {}}], "execution_count": 1}, {"cell_type": "code", "source": "\napi_key = \"y0NlbXIBHDsEhgbRnYuDvatJFJDqv9yt98Uj0WmAUtJA\"\nproject_id = \"b2001e10-b6ff-497e-9afa-adc1eee2b43c\"\nwatsonx_ai_url = \"https://au-syd.ml.cloud.ibm.com\"\n\n\ncos_endpoint = \"https://s3.au-syd.cloud-object-storage.appdomain.cloud\"\ncos_service_crn = \"crn:v1:bluemix:public:cloud-object-storage:global:a/df3e666bca344941b4d3e0c68d38d187:4041aeb9-d4c6-40fa-96da-991bcfa82493::\"\n\n\nfrom ibm_watsonx_ai.client import APIClient\n\ntry:\n    credentials = {\n        \"api_key\": api_key,\n        \"url\": watsonx_ai_url \n    }\n    client = APIClient(credentials=credentials, project_id=project_id)\n    print(\"Watsonx.ai client initialized successfully!\")\nexcept Exception as e:\n    print(f\"Error initializing Watsonx.ai client: {e}\")\n    print(\"Please check your API key, project ID, and URL.\")\n\nimport ibm_boto3\nfrom ibm_botocore.client import Config, ClientError\n\ntry:\n    cos_client = ibm_boto3.client(\n        service_name='s3',\n        ibm_api_key_id=api_key,\n        ibm_service_instance_id=cos_service_crn,\n        config=Config(signature_version='oauth'),\n        endpoint_url=cos_endpoint\n    )\n    print(\"IBM Cloud Object Storage client initialized successfully!\")\nexcept Exception as e:\n    print(f\"Error initializing COS client: {e}\")\n    print(\"Please ensure your COS endpoint and service CRN are correct and accessible.\")", "metadata": {"id": "a6446528-4596-441d-9c39-8e98472ca60c"}, "outputs": [{"name": "stdout", "text": "Watsonx.ai client initialized successfully!\nIBM Cloud Object Storage client initialized successfully!\n", "output_type": "stream"}], "execution_count": 2}, {"cell_type": "code", "source": "\nprint(\"Listing COS buckets...\")\ntry:\n    response = cos_client.list_buckets()\n    for bucket in response['Buckets']:\n        print(f\"  Bucket Name: {bucket['Name']}\")\nexcept Exception as e:\n    print(f\"Error listing buckets: {e}\")", "metadata": {"id": "012276a3-437d-4b6a-b843-3be1e9fc08ea"}, "outputs": [{"name": "stdout", "text": "Listing COS buckets...\n  Bucket Name: aidrivenplagiarismintelligencefor-donotdelete-pr-ktjvnitkzeqpim\n", "output_type": "stream"}], "execution_count": 3}, {"cell_type": "code", "source": "\ntarget_bucket_name = \"aidrivenplagiarismintelligencefor-donotdelete-pr-ktjvnitkzeqpim\" \n\nprint(f\"\\nListing objects in bucket: {target_bucket_name}\")\ntry:\n    response = cos_client.list_objects(Bucket=target_bucket_name)\n    if 'Contents' in response:\n        for obj in response['Contents']:\n            print(f\"  Object Key: {obj['Key']} (Size: {obj['Size']} bytes)\")\n    else:\n        print(f\"No objects found in bucket: {target_bucket_name}\")\nexcept Exception as e:\n    print(f\"Error listing objects in bucket {target_bucket_name}: {e}\")", "metadata": {"id": "8800295a-4aa8-4d63-9050-71a1f1ce9f22"}, "outputs": [{"name": "stdout", "text": "\nListing objects in bucket: aidrivenplagiarismintelligencefor-donotdelete-pr-ktjvnitkzeqpim\n  Object Key: notebook/GranitePlagiarismChecker_zwC31Uwi4.ipynb (Size: 30864 bytes)\n  Object Key: ref1.txt (Size: 192 bytes)\n  Object Key: ref2.txt (Size: 186 bytes)\n  Object Key: submissions/GranitePlagiarismChecker_zwC31Uwi4.ipynb (Size: 20440 bytes)\n  Object Key: user.txt (Size: 255 bytes)\n", "output_type": "stream"}], "execution_count": 4}, {"cell_type": "code", "source": "import os\n\nbucket_name = \"aidrivenplagiarismintelligencefor-donotdelete-pr-ktjvnitkzeqpim\"\nobject_key = \"notebook/GranitePlagiarismChecker_zwC31Uwi4.ipynb\"\nlocal_file_name = \"GranitePlagiarismChecker_zwC31Uwi4.ipynb\" # Name to save it as locally in the notebook environment\n\nprint(f\"Downloading {object_key} from bucket {bucket_name}...\")\ntry:\n    cos_client.download_file(bucket_name, object_key, local_file_name)\n    print(f\"Downloaded {object_key} to {local_file_name}\")\n   \nexcept Exception as e:\n    print(f\"Error downloading {object_key}: {e}\")", "metadata": {"id": "9a949c52-5da6-484a-962d-63b22ae1b036"}, "outputs": [{"name": "stdout", "text": "Downloading notebook/GranitePlagiarismChecker_zwC31Uwi4.ipynb from bucket aidrivenplagiarismintelligencefor-donotdelete-pr-ktjvnitkzeqpim...\nDownloaded notebook/GranitePlagiarismChecker_zwC31Uwi4.ipynb to GranitePlagiarismChecker_zwC31Uwi4.ipynb\n", "output_type": "stream"}], "execution_count": 5}, {"cell_type": "code", "source": "from ibm_boto3 import client\nfrom ibm_botocore.client import Config\n\n\nassignment_file = \"GranitePlagiarismChecker_zwC31Uwi4.ipynb\"\ncos_client.upload_file(Filename=assignment_file,\n                       Bucket=bucket_name,\n                       Key=f\"submissions/{assignment_file}\")\n\nprint(f\"\u2705 Uploaded {assignment_file} to submissions folder in bucket {bucket_name}\")\n", "metadata": {"id": "5b143ef8-1b71-4660-8b7a-64e648e89bd6"}, "outputs": [{"name": "stdout", "text": "\u2705 Uploaded GranitePlagiarismChecker_zwC31Uwi4.ipynb to submissions folder in bucket aidrivenplagiarismintelligencefor-donotdelete-pr-ktjvnitkzeqpim\n", "output_type": "stream"}], "execution_count": 6}, {"cell_type": "code", "source": "from ibm_watsonx_ai.foundation_models import ModelInference\nfrom ibm_watsonx_ai.client import APIClient\n\n\napi_key = \"y0NlbXIBHDsEhgbRnYuDvatJFJDqv9yt98Uj0WmAUtJA\"\nproject_id = \"b2001e10-b6ff-497e-9afa-adc1eee2b43c\"\nwatsonx_ai_url = \"https://au-syd.ml.cloud.ibm.com\"\n\n\ncredentials = {\n    \"url\": watsonx_ai_url,\n    \"api_key\": api_key\n}\n\nclient = APIClient(credentials=credentials, project_id=project_id)\nprint(\"\u2705 Watsonx API client initialized successfully.\")\n\n\nmodel = ModelInference(\n    model_id=\"ibm/granite-13b-instruct-v2\",\n    credentials=credentials,\n    project_id=project_id\n)\nprint(\"\u2705 Granite model loaded successfully.\")\n\nprompt = \"Explain the difference between supervised and unsupervised learning in simple terms.\"\n\nparameters = {\n    \"decoding_method\": \"sample\",\n    \"max_new_tokens\": 100,\n    \"temperature\": 0.5,\n    \"top_k\": 50,\n    \"top_p\": 1\n}\n\nresponse = model.generate(prompt=prompt, params=parameters)\n\nprint(\"\\n\ud83e\udde0 Model Response:\\n\")\nprint(response)\n", "metadata": {"id": "98a63b81-712b-4924-82c9-9a7f97261f4f"}, "outputs": [{"name": "stdout", "text": "\u2705 Watsonx API client initialized successfully.\n", "output_type": "stream"}, {"name": "stderr", "text": "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/utils/utils.py:436: LifecycleWarning: Model 'ibm/granite-13b-instruct-v2' is in deprecated state from 2025-06-18 until 2025-10-15. IDs of alternative models: ibm/granite-3-3-8b-instruct. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n  warn(model_state_warning, category=LifecycleWarning)\n", "output_type": "stream"}, {"name": "stdout", "text": "\u2705 Granite model loaded successfully.\n\n\ud83e\udde0 Model Response:\n\n{'model_id': 'ibm/granite-13b-instruct-v2', 'created_at': '2025-08-02T18:51:14.301Z', 'results': [{'generated_text': 'Supervised learning is a type of machine learning that uses labeled data to learn a function that maps an input to an output. Unsupervised learning is a type of machine learning that does not use labeled data to learn a function that maps an input to an output. ', 'generated_token_count': 54, 'input_token_count': 14, 'stop_reason': 'eos_token', 'seed': 2760205612}], 'system': {'warnings': [{'message': \"Model 'ibm/granite-13b-instruct-v2' is in deprecated state from 2025-06-18. It will be in withdrawn state from 2025-10-15. IDs of alternative models: ibm/granite-3-3-8b-instruct.\", 'id': 'deprecation_warning', 'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp'}, {'message': 'In future implementation, the parameter `parameters.decoding_method` will be ignored and set automatically', 'id': 'param_deprecation'}, {'message': \"This API is legacy. Please consider using '/ml/v1/text/chat' instead.\", 'id': 'api_legacy'}]}}\n", "output_type": "stream"}], "execution_count": 7}, {"cell_type": "code", "source": "with open(\"user.txt\", \"w\") as f:\n    f.write(\"Machine learning is a field of AI that enables computers to learn from data without being explicitly programmed.\")\n\nwith open(\"ref1.txt\", \"w\") as f:\n    f.write(\"Machine learning enables systems to learn and improve from experience without being explicitly programmed.\")\n\nwith open(\"ref2.txt\", \"w\") as f:\n    f.write(\"Artificial Intelligence encompasses machine learning, where data-driven algorithms learn and make predictions.\")\n", "metadata": {"id": "c09891e6-38b1-41c8-99e2-a5acc333c75a"}, "outputs": [], "execution_count": 8}, {"cell_type": "code", "source": "from ibm_watsonx_ai.foundation_models import ModelInference\nimport json\n\n# Step 1: Load the files\ndef read_file(filename):\n    with open(filename, \"r\", encoding=\"utf-8\") as f:\n        return f.read()\n\n# Update filenames if your uploaded files are named differently\nuser_text = read_file(\"user.txt\")\nref1_text = read_file(\"ref1.txt\")\nref2_text = read_file(\"ref2.txt\")\n\n# Step 2: Initialize the model\nmodel = ModelInference(\n    model_id=\"ibm/granite-13b-instruct-v2\",  \n    credentials={\n        \"api_key\": \"y0NlbXIBHDsEhgbRnYuDvatJFJDqv9yt98Uj0WmAUtJA\",\n        \"url\": \"https://au-syd.ml.cloud.ibm.com\"\n    },\n    project_id=\"b2001e10-b6ff-497e-9afa-adc1eee2b43c\"\n)\nprint(\"\u2705 Model Initialized\")\n\n# Step 3: Create prompt\nprompt = f\"\"\"Check this assignment for plagiarism.\nCompare it with the reference materials below.\n\nUser Submission:\n{user_text}\n\nReference 1:\n{ref1_text}\n\nReference 2:\n{ref2_text}\n\"\"\"\n\n# Step 4: Generate and print the result\nresponse = model.generate(prompt=prompt)\n\ntry:\n    if isinstance(response, str):\n        response = json.loads(response)\n\n    print(\"\\n\ud83e\udde0 Plagiarism Detection Report:\\n\")\n    print(response['results'][0]['generated_text'])\n\n    with open(\"plagiarism_report.txt\", \"w\") as f:\n        f.write(response['results'][0]['generated_text'])\n    print(\"\u2705 Report saved as plagiarism_report.txt\")\n\nexcept Exception as e:\n    print(\"\u26a0\ufe0f Failed to parse response.\")\n    print(\"Raw output:\\n\", response)\n    print(\"\\nError:\\n\", e)\n", "metadata": {"id": "cd9a2139-c48e-47d8-aaad-524aa9ff0eb6"}, "outputs": [{"name": "stderr", "text": "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/utils/utils.py:436: LifecycleWarning: Model 'ibm/granite-13b-instruct-v2' is in deprecated state from 2025-06-18 until 2025-10-15. IDs of alternative models: ibm/granite-3-3-8b-instruct. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n  warn(model_state_warning, category=LifecycleWarning)\n", "output_type": "stream"}, {"name": "stdout", "text": "\u2705 Model Initialized\n\n\ud83e\udde0 Plagiarism Detection Report:\n\n\nYes\n\u2705 Report saved as plagiarism_report.txt\n", "output_type": "stream"}], "execution_count": 10}, {"cell_type": "code", "source": "# --- Setup: Download files from IBM COS ---\nimport ibm_boto3\nfrom ibm_botocore.client import Config\nfrom ibm_watsonx_ai.foundation_models import ModelInference\nimport json\n\n# COS credentials\ncos_endpoint = \"https://s3.au-syd.cloud-object-storage.appdomain.cloud\"\ncos_api_key = \"y0NlbXIBHDsEhgbRnYuDvatJFJDqv9yt98Uj0WmAUtJA\"\ncos_resource_crn = \"crn:v1:bluemix:public:cloud-object-storage:global:a/df3e666bca344941b4d3e0c68d38d187:4041aeb9-d4c6-40fa-96da-991bcfa82493::\"\nbucket_name = \"aidrivenplagiarismintelligencefor-donotdelete-pr-ktjvnitkzeqpim\"\n\ncos = ibm_boto3.client(\n    \"s3\",\n    ibm_api_key_id=cos_api_key,\n    ibm_service_instance_id=cos_resource_crn,\n    config=Config(signature_version=\"oauth\"),\n    endpoint_url=cos_endpoint\n)\n\nfor file in [\"user.txt\", \"ref1.txt\", \"ref2.txt\"]:\n    cos.download_file(Bucket=bucket_name, Key=file, Filename=file)\n    print(f\"\u2705 Downloaded: {file}\")\n\n# --- Read files ---\ndef read_file(filename):\n    with open(filename, \"r\", encoding=\"utf-8\") as f:\n        return f.read()\n\nuser_text = read_file(\"user.txt\")\nref1_text = read_file(\"ref1.txt\")\nref2_text = read_file(\"ref2.txt\")\n\n# --- Initialize the Model ---\nmodel = ModelInference(\n    model_id=\"ibm/granite-13b-instruct-v2\",\n    credentials={\n        \"api_key\": cos_api_key,\n        \"url\": \"https://au-syd.ml.cloud.ibm.com\"\n    },\n    project_id=\"b2001e10-b6ff-497e-9afa-adc1eee2b43c\"\n)\nprint(\"\u2705 Model Initialized\")\n\n# --- Prompt to AI ---\nprompt = f\"\"\"Check this assignment for plagiarism.\nCompare it with the reference materials below.\n\nUser Submission:\n{user_text}\n\nReference 1:\n{ref1_text}\n\nReference 2:\n{ref2_text}\n\"\"\"\n\nresponse = model.generate(prompt=prompt)\n\n# --- Save & Show Report ---\ntry:\n    if isinstance(response, str):\n        response = json.loads(response)\n\n    report = response['results'][0]['generated_text']\n    print(\"\\n\ud83e\udde0 Plagiarism Detection Report:\\n\")\n    print(report)\n\n    with open(\"plagiarism_report.txt\", \"w\", encoding=\"utf-8\") as f:\n        f.write(report)\n\n    print(\"\u2705 Report saved as plagiarism_report.txt\")\n\nexcept Exception as e:\n    print(\"\u26a0\ufe0f Failed to parse response.\")\n    print(\"Raw output:\\n\", response)\n    print(\"\\nError:\\n\", e)\n", "metadata": {"id": "b55d6f4b-e154-458e-90fc-7763f37ca490"}, "outputs": [{"name": "stdout", "text": "\u2705 Downloaded: user.txt\n\u2705 Downloaded: ref1.txt\n\u2705 Downloaded: ref2.txt\n", "output_type": "stream"}, {"name": "stderr", "text": "/opt/conda/envs/Python-RT24.1/lib/python3.11/site-packages/ibm_watsonx_ai/foundation_models/utils/utils.py:436: LifecycleWarning: Model 'ibm/granite-13b-instruct-v2' is in deprecated state from 2025-06-18 until 2025-10-15. IDs of alternative models: ibm/granite-3-3-8b-instruct. Further details: https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-model-lifecycle.html?context=wx&audience=wdp\n  warn(model_state_warning, category=LifecycleWarning)\n", "output_type": "stream"}, {"name": "stdout", "text": "\u2705 Model Initialized\n\n\ud83e\udde0 Plagiarism Detection Report:\n\n\n\u2705 Report saved as plagiarism_report.txt\n", "output_type": "stream"}], "execution_count": 11}, {"cell_type": "code", "source": "", "metadata": {"id": "ba32eda6-5646-4441-b6c1-8d85fb87c886"}, "outputs": [], "execution_count": null}]}